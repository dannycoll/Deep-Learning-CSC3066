{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import revelant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data set, split into data (`x`) and labels (`y`) then scale the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Mixcancer.csv\")\n",
    "y = np.asarray(data.pop('Diagnosis'))\n",
    "x = np.asarray(data)\n",
    "\n",
    "x = preprocessing.MinMaxScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data and labels into test & train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid activation & derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(v):\n",
    "    return 1/(1+np.exp(-v))\n",
    "\n",
    "def sigmoid_derivative(v):\n",
    "    return sigmoid(v)*(1-sigmoid(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relu activation & derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LReLU(x):\n",
    "    return np.where(x > 0, x, x * 0.01)\n",
    "\n",
    "def dLReLU(x):\n",
    "    return np.where(x > 0, 1, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy & derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntrop(o,y):\n",
    "    return (-y*(np.log(o)) - (1-y)* np.log(1-o))\n",
    "\n",
    "def crossEntrDeriv(o,y):\n",
    "  return -(y/o - (1-y)/(1-o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define layer sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_size = 5\n",
    "layer_2_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise variables for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "lr = 0.002\n",
    "batch_size = 128\n",
    "kf = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t0\tTrain Error:\t1.306246587558509\n",
      "Epoch:\t100\tTrain Error:\t0.6998402149086744\n",
      "Epoch:\t200\tTrain Error:\t0.6626495199545903\n",
      "Epoch:\t300\tTrain Error:\t0.6200188197085008\n",
      "Epoch:\t400\tTrain Error:\t0.5752366321649509\n",
      "Fold:\t1\tF-Measure:\t0.870967741935484\n",
      "Epoch:\t0\tTrain Error:\t0.9747014858606823\n",
      "Epoch:\t100\tTrain Error:\t0.7465476859174444\n",
      "Epoch:\t200\tTrain Error:\t0.7125274893340114\n",
      "Epoch:\t300\tTrain Error:\t0.6978664407176451\n",
      "Epoch:\t400\tTrain Error:\t0.69182465300081\n",
      "Fold:\t2\tF-Measure:\t0.7883211678832116\n",
      "Epoch:\t0\tTrain Error:\t1.0621879726893853\n",
      "Epoch:\t100\tTrain Error:\t0.5174666735248896\n",
      "Epoch:\t200\tTrain Error:\t0.4354310312818815\n",
      "Epoch:\t300\tTrain Error:\t0.368040223079348\n",
      "Epoch:\t400\tTrain Error:\t0.31571064721199177\n",
      "Fold:\t3\tF-Measure:\t0.9321533923303835\n",
      "Epoch:\t0\tTrain Error:\t1.0830012565921483\n",
      "Epoch:\t100\tTrain Error:\t0.7247502349042542\n",
      "Epoch:\t200\tTrain Error:\t0.7013273384371397\n",
      "Epoch:\t300\tTrain Error:\t0.6915168303442658\n",
      "Epoch:\t400\tTrain Error:\t0.6874581008189713\n",
      "Fold:\t4\tF-Measure:\t0.7834549878345499\n",
      "Epoch:\t0\tTrain Error:\t0.9169107315613968\n",
      "Epoch:\t100\tTrain Error:\t0.6322783216337319\n",
      "Epoch:\t200\tTrain Error:\t0.5846873471215798\n",
      "Epoch:\t300\tTrain Error:\t0.530889290496562\n",
      "Epoch:\t400\tTrain Error:\t0.47549476137794394\n",
      "Fold:\t5\tF-Measure:\t0.9173789173789174\n",
      "Epoch:\t0\tTrain Error:\t1.6190027051117275\n",
      "Epoch:\t100\tTrain Error:\t0.5686501196879348\n",
      "Epoch:\t200\tTrain Error:\t0.5280728083966422\n",
      "Epoch:\t300\tTrain Error:\t0.48921623656532753\n",
      "Epoch:\t400\tTrain Error:\t0.45326803237628305\n",
      "Fold:\t6\tF-Measure:\t0.9146341463414634\n",
      "Epoch:\t0\tTrain Error:\t0.9112840507568779\n",
      "Epoch:\t100\tTrain Error:\t0.7021168846593558\n",
      "Epoch:\t200\tTrain Error:\t0.6542096917089938\n",
      "Epoch:\t300\tTrain Error:\t0.6014415544504604\n",
      "Epoch:\t400\tTrain Error:\t0.5404867966186369\n",
      "Fold:\t7\tF-Measure:\t0.9310344827586207\n",
      "Epoch:\t0\tTrain Error:\t0.7305885154942291\n",
      "Epoch:\t100\tTrain Error:\t0.679119249067586\n",
      "Epoch:\t200\tTrain Error:\t0.6485621088939848\n",
      "Epoch:\t300\tTrain Error:\t0.6209262319603516\n",
      "Epoch:\t400\tTrain Error:\t0.5923292602438311\n",
      "Fold:\t8\tF-Measure:\t0.7872860635696821\n",
      "Epoch:\t0\tTrain Error:\t0.8354825662569556\n",
      "Epoch:\t100\tTrain Error:\t0.7041451225107949\n",
      "Epoch:\t200\tTrain Error:\t0.6721683476213569\n",
      "Epoch:\t300\tTrain Error:\t0.6419113928346594\n",
      "Epoch:\t400\tTrain Error:\t0.6059762732624489\n",
      "Fold:\t9\tF-Measure:\t0.8571428571428571\n",
      "Epoch:\t0\tTrain Error:\t0.8853956016790362\n",
      "Epoch:\t100\tTrain Error:\t0.6804117832176331\n",
      "Epoch:\t200\tTrain Error:\t0.6726144283379413\n",
      "Epoch:\t300\tTrain Error:\t0.6644194777885056\n",
      "Epoch:\t400\tTrain Error:\t0.6550069443082431\n",
      "Fold:\t10\tF-Measure:\t0.8977272727272727\n",
      "Macro-F-Measure:\t0.8680101029902442\n"
     ]
    }
   ],
   "source": [
    "n = len(x_train[1])\n",
    "train_E = []\n",
    "test_E = []\n",
    "train_Acc = []\n",
    "test_Acc = []\n",
    "f_measures = []\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(x):\n",
    "  w1 = np.random.uniform(-1,1,[x_train.shape[1],layer_1_size])\n",
    "  w2 = np.random.uniform(-1,1,[layer_1_size])\n",
    "\n",
    "  b1 = np.random.uniform(-1,1,[layer_1_size])\n",
    "  b2 = np.random.uniform(-1,1,[layer_2_size])\n",
    "  for epoch in range(epochs):\n",
    "    for i in range(0, x_train.shape[0], batch_size):\n",
    "      x_batch = x_train[i:i + batch_size,:]\n",
    "      y_batch = y_train[i:i + batch_size]\n",
    "      if b1.shape != [layer_1_size,]:\n",
    "        b1 = b1.reshape([layer_1_size,])\n",
    "      if w2.shape != [layer_1_size,]:\n",
    "        w2 = w2.reshape([layer_1_size,])\n",
    "      in1 = x_batch@w1+b1\n",
    "      out1 = LReLU(in1)\n",
    "      in2 = out1@w2+b2\n",
    "      out2 = sigmoid(in2)\n",
    "\n",
    "      dEdO2 = crossEntrDeriv(out2,y_batch)\n",
    "      dO2dIn2 = sigmoid_derivative(in2)\n",
    "      dO1dIn1 = dLReLU(in1)\n",
    "      \n",
    "      dEdW2 = 1/n * out1.T@(dEdO2*dO2dIn2)\n",
    "      dEdB2 = 1/n * np.ones([1,x_batch.shape[0]])@(dEdO2*dO2dIn2)\n",
    "      \n",
    "      w2 = w2.reshape(1,w2.shape[0])\n",
    "\n",
    "      dEdW1 = 1/n * x_batch.T@((np.reshape(dEdO2*dO2dIn2,[len(x_batch),1])@w2)*dO1dIn1)\n",
    "      dEdB1 = 1/n * np.ones([1,x_batch.shape[0]])@((np.reshape(dEdO2*dO2dIn2,[len(x_batch),1])@w2)*dO1dIn1)\n",
    "\n",
    "      w1 -= lr*dEdW1\n",
    "      w2 -= lr*dEdW2\n",
    "      b1 -= lr*dEdB1[0,:]\n",
    "      b2 -= lr*dEdB2\n",
    "    if epoch % 100 == 0:\n",
    "      error_train = crossEntrop(out2,y_batch)\n",
    "      b1 = b1.reshape([layer_1_size,])\n",
    "      w2 = w2.reshape([layer_1_size,])\n",
    "      train_E.append(error_train.mean())\n",
    "      print('Epoch:\\t%s\\tTrain Error:\\t%s'%(epoch,train_E[-1]))\n",
    "      prediction_test = np.where(sigmoid(LReLU(x_test@w1+b1)@w2+b2) > 0.5,1,0)\n",
    "  fold +=1\n",
    "  f_measure = metrics.f1_score(y_test,prediction_test)\n",
    "  f_measures.append(f_measure)\n",
    "  print('Fold:\\t%s\\tF-Measure:\\t%s'%(fold,f_measure))\n",
    "print('Macro-F-Measure:\\t%s'%(np.array(f_measures).mean()))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
